\documentclass{easychair}

\usepackage{setspace}

\begin{document}

\title{Distributed programming via safe closure passing}

% \titlerunning{} has to be set to either the main title or its shorter
% version for the running heads. When processed by
% EasyChair, this command is mandatory: a document without \titlerunning
% will be rejected by EasyChair

\titlerunning{Safe closure passing}

% Authors are joined by \and. Their affiliations are given by \inst, which indexes
% into the list defined using \institute
%
\author{
  Philipp Haller\inst{1}
\and
  Heather Miller\inst{2}
}

% Institutes for affiliations are also joined by \and,
\institute{
  KTH Royal Institute of Technology,
  Sweden\\
  \email{phaller@kth.se}
\and
  EPFL,
  Switzerland\\
  \email{heather.miller@epfl.ch}\\
}

%  \authorrunning{} has to be set for the shorter version of the authors' names;
% otherwise a warning will be rendered in the running heads. When processed by
% EasyChair, this command is mandatory: a document without \authorrunning
% will be rejected by EasyChair

\authorrunning{Haller and Miller}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}

Programming systems incorporating aspects of functional programming, e.g.,
higher-order functions, are becoming increasingly popular for large-scale
distributed programming. New frameworks such as Apache Spark leverage
functional techniques to provide high-level, declarative APIs for in-memory
data analytics, often outperforming traditional ``big data'' frameworks like
Hadoop MapReduce. However, widely-used programming models remain rather
ad-hoc; aspects such as implementation trade-offs, static typing, and semantics
are not yet well-understood. We present a new asynchronous programming model
that has at its core several principles facilitating functional processing of
distributed data. The emphasis of our model is on simplicity, performance,
expressiveness, and a well-defined operational semantics. The primary means of
communication is by passing functions (closures) to distributed, immutable
data. To ensure safe and efficient distribution of closures, our model
leverages both syntactic and type-based restrictions. We report on a prototype
implementation as an embedded domain-specific language in Scala. Finally, we
present first results practically evaluating our implementation.

\end{abstract}

%------------------------------------------------------------------------------
\section{Introduction}
\label{sec:introduction}

Programming systems for large-scala data processing are increasingly embracing
functional programming, i.e., programming with first-class functions and
higher-order functions. Arguably, one of the first widely-used programming
models for ``big data'' processing making use of concepts from functional
programming is Google's MapReduce~\cite{DeanG08}. Indeed, \cite{Lammel08}
shows a precise executable semantics of MapReduce in Haskell. While leveraging
functional programming \emph{concepts}, popular implementations of the
MapReduce model, such as Hadoop MapReduce\footnote{See \url{http://hadoop.apache.org/}}
for Java, have been developed without making
use of functional \emph{language features} such as closures. In contrast, a new generation
of programming systems for large-scale data processing, such as
Apache Spark~\cite{Zaharia2012},
Twitter's Scalding\footnote{See \url{https://github.com/twitter/scalding/}},
and Scoobi\footnote{See \url{http://nicta.github.io/scoobi/}} build on functional
language features in order to provide high-level, declarative APIs.

However, these programming systems suffer from several problems that
negatively affect their usage, maintainance, and optimization:

\begin{itemize}

\item Their APIs cannot statically prevent \emph{common usage errors}. As a result, users are often
      confronted with runtime errors that are hard to debug. A common example is
      unsafe closure serialization~\cite{MillerHO14}.

\item Typically, only high-level user-facing abstractions are statically
      typed. Static types are quickly lost in deeper layers of the system,
      which complicates its \emph{maintainance}. For example, code refactorings
      are more error-prone.

% communicating messages with incorrect types can cause deadlocks

\item The absence of certain kinds of static type information precludes systems-centric \emph{optimizations}.
      Importantly, type-based static meta-programming enables fast serialization~\cite{MillerHBO13}, but this is
      only possible if also lower layers (namely those dealing with object serialization) are statically typed.
      Several studies~\cite{Carpenter1999,Maassen1999,Philippsen2000,Welsh2000} report on the high
      overhead of serialization in widely-used runtime environments such as the JVM. This overhead is so
      important in practice that popular systems, like Spark~\cite{Zaharia2012} and Akka~\cite{Akka},
      leverage alternative serialization frameworks such as Protocol Buffers~\cite{Protobuf} (Google),
      Apache Avro~\cite{Avro}, or Kryo~\cite{Kryo}.

\end{itemize}

This paper presents a new asynchronous programming model for functional
processing of distributed data. The goal of our model is twofold: first, we
propose to address the above problems through a novel combination of:

\begin{itemize}

\item \emph{Safe closures;} to prevent common usage errors. Closures that are not
      guaranteed to be serializable are rejected at compile time;

\item \emph{A statically-typed implementation of a generic distributed, persistent data structure.}
      Preserving static types through more system layers improves maintainability and
      enables the optimization of performance-critical parts, such as serialization.

\end{itemize}

A second goal of our model is to better understand programming systems such as Spark, Scalding, and
Scoobi, by incorporating several of their core principles; namely, immutable
distributed data and distributed closure passing. By focussing on simplicity,
expressiveness, and performance (and ignoring many of the more ad-hoc
refinements of the mentioned programming models) our
programming model--together with its prototype implementation--enables exploring
implementation trade-offs, and capturing the semantics of the core constructs more
precisely. The primary means of communication is by passing functions (closures)
to distributed, immutable data.

To ensure safe and efficient distribution of closures, our model leverages
both syntactic and type-based restrictions. For instance, closures sent to
remote nodes are required to conform to the restrictions imposed by the
so-called ``Spore'' abstraction that the authors presented in previous
work~\cite{MillerHO14}. Among others, the syntax and static semantics of
Spores can guarantee the absence of runtime serialization errors due to
closure environments that are not serializable.


\section{Overview}
\label{sec:overview}

The programming model has a few basic abstractions at its center: first, the
so-called \emph{silo}. A silo is a typed data container. It is stationary in the
sense that it does not move between machines. A silo remains on the machine
where it was created. Data stored in a silo is typically loaded from stable
storage, such as a distributed file system. A program operating on data stored
in a silo can only do so using a reference to the silo, a so-called \emph{SiloRef}.
Similar to a proxy object, a SiloRef represents, and allows interacting with,
a silo possibly located on a remote node. Some programming patterns require
combining data contained in silos located on different nodes (e.g., joins). To
support such patterns, our model includes a \emph{pump} primitive for emitting
data to silos on arbitrary nodes (explained further below).

A SiloRef has the following main operations:
\begin{verbatim}
trait SiloRef[T] {
  def apply(s: Spore[T, S]): SiloRef[S]
  def send(): Future[T]
}
\end{verbatim}

\paragraph{Apply}

The \verb|apply| method takes a spore, a kind of closure (see below for an overview), that is to be applied to
the data in the silo of the receiver SiloRef. Rather than immediately sending
the spore across the network, and waiting for the operation to finish, the
apply method is \emph{lazy}. It immediately returns a SiloRef that refers to the
result silo.

To realize something like the \verb|map| combinator of a (distributed) collection using \verb|apply|,
it is helpful to think of the Spore argument to \verb|apply| (``s'') as the composition of a
user-defined function passed to the \verb|map| combinator with the actual implementation of \verb|map|.

\paragraph{Example}

\begin{verbatim}
val ref: SiloRef[List[Int]] = ...
val userFun: Int => String = ...
val mapFun: (Int => String) => List[Int] => List[String] = ...
val ref2: SiloRef[List[String]] =
      ref.apply(mapFun(userFun))
\end{verbatim}

In the above example, the higher-order \verb|mapFun| function is expressed in curried
style where the user's function argument is passed as the first argument.
Applying \verb|mapFun| to a function of type \verb|Int => String| returns a function of type
\verb|List[Int] => List[String]|.

The result of invoking \verb|apply| is another SiloRef, which has a reference to the
Spore and the SiloRef that it was derived from. Note that this is semantically
the same as programming with normal functional data structures, where a new
data structure is defined by a transformation of an original data structure.

\paragraph{Send}

The \verb|send| method takes no argument, and returns a future. Unlike
\verb|apply|, \verb|send| is \emph{eager} (readers familiar with the concept
of \emph{views} might recognize a similarity to forcing a view). That is, it
sends whatever operations are queued up (by invocations of \verb|apply|) on a
given SiloRef to the node that contains the corresponding silo, and kicks of
the materialization of the result silo. Once the materialization is done, the
future returned by \verb|send| is completed.

\paragraph{Example}

\begin{verbatim}
val ref2 = ref1.apply(s)  // lazy
val fut  = ref2.send()    // eager
\end{verbatim}
\noindent
The invocation of \verb|send| kicks off the following sequence of actions:
\begin{enumerate}
\item A ``send'' control message is sent to the node where ref2's silo is located.
\item Since \verb|ref2| is derived from \verb|ref1|, \verb|ref1|'s silo is located on the same node. Thus, the runtime demands
      \verb|ref1| to be materialized; once this is done, spore \verb|s| is applied, populating \verb|ref2|'s silo (on the same node).
\item Once \verb|ref2|'s silo is materialized, its data is sent to the master node, completing the \verb|fut| future.
\end{enumerate}
\noindent
Note that since a \verb|send| operation sends the data of a silo to the master
node, it should only be invoked on silos containing small bits of data.



\subsection{Leveraging static type information}


\section{Implementation and preliminary experimental results}
\label{sec:experimental}


\section{Related work}

% Recently, there have been efforts (e.g., \cite{}) to make communication APIs
% more typed, however, these approaches typically don't address the problem of
% lower system layers being untyped (it's just the top-level API). Our approach
% in addition aims to actively exploit the additional static type info
% throughout the stack, in particular for optimizing remote communication.

[TODO: rewrite] Related to everything that Spores are related to. But then
also to things like MBrace (ref?).


\section{Conclusion and Future Work}
\label{sec:conclusion}

%------------------------------------------------------------------------------
% Refs:
%
\begin{spacing}{0.9}
\bibliographystyle{plain}
\bibliography{bib}
\end{spacing}

\end{document}
